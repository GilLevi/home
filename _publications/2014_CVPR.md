---
title: "A Piggyback Representation for Action Recognition"
collection: publications
permalink: /publication/2014_CVPR
excerpt: '[<font color="SkyBlue">Download paper</font>](https://osnathassner.github.io/talhassner/files/CVPR2014_semvlad.pdf)'
date: 2014-06-01
venue: 'IEEE International Workshop on Deep-Vision, at the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), Columbus, Ohio'
paperurl: ''
citation: Lior Wolf, Yair Hanani, Tal Hassner. (2014). &quot;A Piggyback Representation for Action Recognition.&quot; <i>IEEE International Workshop on Deep-Vision, at the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), Columbus, Ohio</i>'
---

<img src='https://osnathassner.github.io/talhassner/images/Piggyback Representation - Icon.jpg'>

Abstract
------
In video understanding, the spatial patterns formed by local space-time interest points hold discriminative information. We encode these spatial regularities using a word2vec neural network, a recently proposed tool in the field of text processing. Then, building upon recent accumulator based image representation solutions, input videos are represented in a hybrid manner: the appearance of local space time interest points is used to collect and associate the learned descriptors, which capture the spatial patterns. Promising results are shown on recent action recognition benchmarks, using well established methods as the underlying appearance descriptors.


[Download paper here](https://osnathassner.github.io/talhassner/files/CVPR2014_semvlad.pdf)
