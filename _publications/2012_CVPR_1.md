---
title: "On SIFTs and their Scales"
collection: publications
permalink: /publication/2012_CVPR_1
excerpt: '[Download paper here](https://osnathassner.github.io/talhassner/projects/siftscales/OnSiftsAndTheirScales-CVPR12.pdf)'
date: 2012-06-20
venue: 'IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), Rhode Island'
paperurl: ''
citation: 'Tal Hassner, Viki Mayzels, and Lihi Zelnik-Manor. (2012). &quot;On SIFTs and their Scales.&quot; <i>IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), Rhode Island</i>.'
---

bstract
------
Scale invariant feature detectors often find stable scales in only a few image pixels. Consequently, methods for feature matching typically choose one of two extreme options: matching a sparse set of scale invariant features, or dense matching using arbitrary scales. In this paper we turn our attention to the overwhelming majority of pixels, those where stable scales are not found by standard techniques. We ask, is scale-selection necessary for these pixels, when dense, scale-invariant matching is required and if so, how can it be achieved? We make the following contributions: (i) We show that features computed over different scales, even in low-contrast areas, can be different; selecting a single scale, arbitrarily or otherwise, may lead to poor matches when the images have different scales. (ii) We show that representing each pixel as a set of SIFTs, extracted at multiple scales, allows for far better matches than singlescale descriptors, but at a computational price. Finally, (iii) we demonstrate that each such set may be accurately represented by a low-dimensional, linear subspace. A subspaceto-point mapping may further be used to produce a novel descriptor representation, the Scale-Less SIFT (SLS), as an alternative to single-scale descriptors. These claims are verified by quantitative and qualitative tests, demonstrating significant improvements over existing methods.

<br/>Reference (Extended journal version): Tal Hassner, Shay Filosof, Viki Mayzels, and Lihi Zelnik-Manor, SIFTing through Scales, IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI), 39(7): 1431-1443 (2017)
<br/>[PDF](https://osnathassner.github.io/talhassner/projects/siftscales/HassneretalTPAMI16.pdf)
<br/>[BibTeX](https://osnathassner.github.io/talhassner/projects/siftscales/BibTeXJournal.txt) 

<br/>Reference (conference paper): Tal Hassner, Viki Mayzels, and Lihi Zelnik-Manor, On SIFTs and their Scales, IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), Rhode Island, June 2012
<br/>[PDF](https://osnathassner.github.io/talhassner/projects/siftscales/OnSiftsAndTheirScales-CVPR12.pdf)
<br/>[BibTeX](https://osnathassner.github.io/talhassner/projects/siftscales/BibTeX.tx) 

<br/>
<img src='https://osnathassner.github.io/talhassner/images/New - icon.jpg' width='80'> **(13 June 2016)**
<br/>Extended journal version accepted to IEEE-TPAMI. See above for reference details. 

<br/>
<img src='https://osnathassner.github.io/talhassner/images/New - icon.jpg' width='80'>
Followup project on [dense correspondences between scenes and scales](https://osnathassner.github.io/talhassner/publication/2016_TPAMI) has been posted, including code and related documents.

Slides from the ICCV'13 tutorial on Dense Image Correspondences for Computer Vision, Sydney Australia, Dec. 2013. ([PDF](https://osnathassner.github.io/talhassner/projects/siftscales/scalemaps/DenseCorrespondences_web.pdf))

<br/>
| Left input image | Right input image | 
|:--------:|:-------:|
| <img src='https://osnathassner.github.io/talhassner/projects/siftscales/flowers_left.jpg'> | <img src='https://osnathassner.github.io/talhassner/projects/siftscales/iflowers_right.jpg'>   | 
| <img src='https://osnathassner.github.io/talhassner/projects/siftscales/flowers_warp_dsift.jpg'> | <img src='https://osnathassner.github.io/talhassner/projects/siftscales/flowers_warp_sls.jpg'>   |
|:--------:|:-------:|
| Warp with DSIFT | Warp+crop with our SLS |
